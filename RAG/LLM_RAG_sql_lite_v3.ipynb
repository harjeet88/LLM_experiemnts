{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmTB8Vn/YQODi//aXSwuQe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harjeet88/LLM_experiemnts/blob/main/RAG/LLM_RAG_sql_lite_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qNzSuveMupb-"
      },
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel, pipeline\n",
        "from bs4 import BeautifulSoup\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model and tokenizer\n",
        "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjy1-7fCuvSl",
        "outputId": "24d79862-d058-4407-f348-f34522ecc651"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the text generation model and pipeline\n",
        "generation_model_name = \"EleutherAI/gpt-neo-1.3B\"\n",
        "generation_tokenizer = AutoTokenizer.from_pretrained(generation_model_name)\n",
        "generation_model = pipeline(\"text-generation\", model=generation_model_name, tokenizer=generation_tokenizer)\n"
      ],
      "metadata": {
        "id": "iWVAr6DHLAWt",
        "outputId": "83975bb2-d167-4777-a6ed-402bbbf1d092",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up SQLite connection\n",
        "conn = sqlite3.connect('rag_website_example.db')\n",
        "cur = conn.cursor()"
      ],
      "metadata": {
        "id": "JFa9KwuT_lKx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create table for storing documents and their embeddings\n",
        "cur.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS documents (\n",
        "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    content TEXT,\n",
        "    embedding BLOB\n",
        ");\n",
        "\"\"\")\n",
        "conn.commit()"
      ],
      "metadata": {
        "id": "RcY04vOe_o1R"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to compute embeddings\n",
        "def compute_embedding(text):\n",
        "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()  # Use mean pooling to get a fixed-size embedding"
      ],
      "metadata": {
        "id": "caj4eQyBxli4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to scrape text content from a website\n",
        "def scrape_website(url):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    paragraphs = soup.find_all('p')\n",
        "    return \"\\n\".join([para.get_text() for para in paragraphs])\n",
        "\n",
        "# Function to insert document into the database\n",
        "def insert_document(content):\n",
        "    embedding = compute_embedding(content).tobytes()  # Convert numpy array to bytes\n",
        "    cur.execute(\"INSERT INTO documents (content, embedding) VALUES (?, ?)\", (content, embedding))\n",
        "    conn.commit()"
      ],
      "metadata": {
        "id": "gWw3es5eu7__"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to retrieve documents based on query\n",
        "def retrieve_documents(query, top_k=3):\n",
        "    query_embedding = compute_embedding(query)\n",
        "    cur.execute(\"SELECT content, embedding FROM documents\")\n",
        "    rows = cur.fetchall()\n",
        "\n",
        "    # Compute cosine similarity between query embedding and document embeddings\n",
        "    similarities = []\n",
        "    for content, embedding in rows:\n",
        "        doc_embedding = np.frombuffer(embedding, dtype=np.float32)\n",
        "        similarity = np.dot(query_embedding, doc_embedding) / (np.linalg.norm(query_embedding) * np.linalg.norm(doc_embedding))\n",
        "        similarities.append((content, similarity))\n",
        "\n",
        "    # Sort by similarity and return top_k results\n",
        "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "    return [content for content, _ in similarities[:top_k]]"
      ],
      "metadata": {
        "id": "NnQhIlRdxQ-K"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate a response\n",
        "# Function to generate a response\n",
        "def generate_response(query):\n",
        "    retrieved_docs = retrieve_documents(query)\n",
        "    combined_text = \" \".join(retrieved_docs)\n",
        "    response = generation_model(f\"Query: {query}\\nDocuments: {combined_text}\\nAnswer:\", max_new_tokens=100)\n",
        "    return response[0]['generated_text']"
      ],
      "metadata": {
        "id": "Ys0AbROwAheF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example website URL\n",
        "url = \"https://en.wikipedia.org/wiki/Harry_Potter\"\n",
        "content = scrape_website(url)\n",
        "insert_document(content)\n",
        "\n",
        "# Example query\n",
        "query = \"Tell me about the content on the website.\"\n",
        "response = generate_response(query)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "mSehuY86-hgr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba3ea69f-8ee4-4965-d299-17767446d853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (39632 > 2048). Running this sequence through the model will result in indexing errors\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Close the database connection\n",
        "cur.close()\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "hZB5hnzk-rBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vRfHfHH3-9T9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}